{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTuneLOOCV_w_wo_pause.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshwinDeshpande96/Measuring_the_Impact_of_Verbal_Disfluency_Tags_on_Automated_Dementia_Detection/blob/master/FineTuneLOOCV_w_wo_pause.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbcHDs-cyj-s"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive/Research/ADReSSo\n",
        "# %cd /content/drive/My\\ Drive/Admission/UIC/Research/Python/Dementia-Detection/Disfluency-Detection/english-fisher-annotations\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8HlwwyCPJSX"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5eq2FbbxUkH"
      },
      "source": [
        "# models = ['Bert', 'Roberta', 'DistilBERT']\n",
        "# _ = [print(f\"[{i + 1}] {m}\") for i, m in enumerate(models)]\n",
        "# model_num = int(input(\"Choose model: \")) - 1\n",
        "# if model_num not in range(len(models)):\n",
        "#     raise Exception(\"Incorrect model chosen.\")\n",
        "\n",
        "# model_name = models[model_num]\n",
        "#####################################################################\n",
        "import random\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from google.colab import drive\n",
        "import datetime\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "import time\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "from sklearn.model_selection import KFold\n",
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "#################### Global Variables ####################\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "UNUSED_TOKEN = {1: '[unused0]',\n",
        "                2: '[unused1]',\n",
        "                3: '[unused2]'}\n",
        "to_categorical = {'Control': 0,\n",
        "                  'Dementia': 1}\n",
        "\n",
        "#################### Read Data ####################\n",
        "\n",
        "\n",
        "\n",
        "#################### Train and Test Sets ####################\n",
        "\n",
        "# train_text, temp_text, train_labels, temp_labels = train_test_split(df['transcript'], df['dx'],\n",
        "#                                                                     random_state=seed_val,\n",
        "#                                                                     test_size=0.3,\n",
        "#                                                                     stratify=df['dx'])\n",
        "\n",
        "\n",
        "#################### BERT features ####################\n",
        "\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def get_bert_tokenizer():\n",
        "    from transformers import BertTokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_basic_tokenize=False)\n",
        "    tokenizer.add_special_tokens({ \"additional_special_tokens\": [ \"[unused0]\", \"[unused1]\", \"[unused2]\" ] })\n",
        "    return tokenizer\n",
        "\n",
        "\n",
        "def get_roberta_tokenizer():\n",
        "    from transformers import RobertaTokenizer\n",
        "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_basic_tokenize=False)\n",
        "    return tokenizer\n",
        "\n",
        "def get_distilbert_tokenizer():\n",
        "    from transformers import DistilBertTokenizer\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_basic_tokenize=False)\n",
        "    return tokenizer\n",
        "\n",
        "\n",
        "def encode_sentence(transcript, tokenizer, include_pauses=True):\n",
        "    transcript = transcript.lower()\n",
        "    if include_pauses:\n",
        "        transcript = re.sub(r\"\\[P1\\]\", \"[unused0]\", transcript)\n",
        "        transcript = re.sub(r\"\\[P2\\]\", \"[unused1]\", transcript)\n",
        "        transcript = re.sub(r\"\\[P3\\]\", \"[unused2]\", transcript)\n",
        "    else:\n",
        "        transcript = re.sub(r\"\\[P\\d\\]\", \"\", transcript)\n",
        "    transcript = re.sub(r\"\\.\", \"[PAD]\", transcript)\n",
        "    tokens = list(tokenizer.tokenize(transcript))\n",
        "    tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    return token_ids\n",
        "\n",
        "\n",
        "def add_padding(input_word_ids, max_seq_len):\n",
        "    input_type = []\n",
        "    for idx, embedding in enumerate(input_word_ids):\n",
        "        embedding_len = len(embedding)\n",
        "        e_input_type = np.ones(embedding_len, dtype=np.int64).tolist()\n",
        "        if embedding_len < max_seq_len:\n",
        "            zeros = np.zeros(max_seq_len - embedding_len, dtype=np.int64).tolist()\n",
        "            e_input_type += zeros\n",
        "            embedding += zeros\n",
        "        elif embedding_len > max_seq_len:\n",
        "            embedding = embedding[:max_seq_len - 1] + [102]\n",
        "            e_input_type = e_input_type[:max_seq_len]\n",
        "        input_type.append(torch.tensor([e_input_type]))\n",
        "        input_word_ids[idx] = torch.tensor([embedding])\n",
        "    return {'input_ids': input_word_ids, 'attention_mask': input_type}\n",
        "\n",
        "\n",
        "def bert_encode(transcripts, tokenizer, max_seq_len, include_pauses=True):\n",
        "    input_word_ids = [encode_sentence(s, tokenizer, include_pauses=include_pauses)\n",
        "                      for s in transcripts]\n",
        "    input_word_ids = add_padding(input_word_ids, max_seq_len)\n",
        "    return input_word_ids\n",
        "############################# Models ##################################\n",
        "def get_bert_model():\n",
        "    from transformers import BertForSequenceClassification\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        \"bert-base-uncased\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
        "        num_labels=2,  # The number of output labels--2 for binary classification.\n",
        "        # You can increase this for multi-class tasks.\n",
        "        output_attentions=False,  # Whether the model returns attentions weights.\n",
        "        output_hidden_states=False,  # Whether the model returns all hidden-states.\n",
        "    )\n",
        "    model.cuda()\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_roberta_model():\n",
        "    from transformers import RobertaForSequenceClassification\n",
        "    model = RobertaForSequenceClassification.from_pretrained(\n",
        "        \"roberta-base\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
        "        num_labels=2,  # The number of output labels--2 for binary classification.\n",
        "        # You can increase this for multi-class tasks.\n",
        "        output_attentions=False,  # Whether the model returns attentions weights.\n",
        "        output_hidden_states=False,  # Whether the model returns all hidden-states.\n",
        "    )\n",
        "    model.cuda()\n",
        "    return model\n",
        "\n",
        "def get_distilbert_model():\n",
        "    from transformers import DistilBertForSequenceClassification\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\n",
        "        \"distilbert-base-uncased\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
        "        num_labels=2,  # The number of output labels--2 for binary classification.\n",
        "        # You can increase this for multi-class tasks.\n",
        "        output_attentions=False,  # Whether the model returns attentions weights.\n",
        "        output_hidden_states=False,  # Whether the model returns all hidden-states.\n",
        "    )\n",
        "    model.cuda()\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCl4lyPgxLWh"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/Research/ADReSSo\n",
        "\n",
        "def pause2020():\n",
        "    df = pd.read_pickle('data2020_pause.pickle')\n",
        "    experiments = ['asr_transcript_w_pause', 'gold_transcript_w_pause']\n",
        "    df.dx = df.dx.apply(lambda x: to_categorical[x])\n",
        "    X1 = df.asr_transcript_w_pause.to_numpy()\n",
        "    X2 = df.gold_transcript_w_pause.to_numpy()\n",
        "    Xs = [X1, X2]\n",
        "    y = df.dx.to_numpy()\n",
        "    return df, experiments, Xs, y\n",
        "\n",
        "def pause2021():\n",
        "    df = pd.read_pickle('data.pickle')\n",
        "    experiments = ['transcript']\n",
        "    df.dx = df.dx.apply(lambda x: to_categorical[x])\n",
        "    X1 = df.transcript.to_numpy()\n",
        "    Xs = [X1]\n",
        "    y = df.dx.to_numpy()\n",
        "    return df, experiments, Xs, y\n",
        "  \n",
        "def new_data():\n",
        "    df = pd.read_pickle('new_data.pickle')\n",
        "    experiments = ['asr_text', \"e_tagged\", \"rep_eremoved\", \"ret_eremoved\", \"both_eremoved\"]\n",
        "    df.dx = df.dx.apply(lambda x: to_categorical[x])\n",
        "    X1 = df.asr_text.to_numpy()\n",
        "    X2 = df.e_tagged.to_numpy()\n",
        "    X3 = df.rep_eremoved.to_numpy()\n",
        "    X4 = df.ret_eremoved.to_numpy()\n",
        "    X5 = df.both_eremoved.to_numpy()\n",
        "    Xs = [X1, X2, X3, X4, X5]\n",
        "    y = df.dx.to_numpy()\n",
        "    return df, experiments, Xs, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbF4kWxnIbU6"
      },
      "source": [
        "model_name = \"bert\"\n",
        "from collections import OrderedDict\n",
        "lr = 2e-5\n",
        "max_seq_len = 256\n",
        "epochs = 8\n",
        "# epochs = 1\n",
        "batch_size_tr = 16\n",
        "batch_size_ts = 32\n",
        "seed_val = 0\n",
        "loo = LeaveOneOut()\n",
        "df, experiments, Xs, y = pause2021()\n",
        "accuracy_dict = OrderedDict(zip(experiments, [[] for _ in range(len(experiments))]))\n",
        "f1_dict = OrderedDict(zip(experiments, [[] for _ in range(len(experiments))]))\n",
        "\n",
        "print(f\"SEED: {seed_val}\\nMODEL: {model_name}\\nBATCH SIZE TR: {batch_size_tr}\\nBATCH SIZE TS: {batch_size_ts}\\nLEARNING RATE: {lr}\\nEMBEDDING LEN: {max_seq_len}\\nEPOCH: {epochs}\")\n",
        "# model_name, lr, max_seq_len, epochs, batch_size_tr, batch_size_ts, seed_val, include_pauses = param_list\n",
        "for seed_val in [0, 42, 23]: #, 17, 19, 111]:\n",
        "    for name, X in zip(experiments, Xs):\n",
        "        for include_pauses in [True, False]:\n",
        "            random.seed(seed_val)\n",
        "            np.random.seed(seed_val)\n",
        "            torch.manual_seed(seed_val)\n",
        "            torch.cuda.manual_seed_all(seed_val)\n",
        "            total_preds = []\n",
        "            total_target = []\n",
        "            kf = KFold(n_splits=5, random_state=seed_val, shuffle=True)\n",
        "            pred = []\n",
        "            target = []\n",
        "            total_val_acc = []\n",
        "            total_val_f1 = []\n",
        "            for train_index, test_index in kf.split(X):\n",
        "                random.seed(seed_val)\n",
        "                np.random.seed(seed_val)\n",
        "                torch.manual_seed(seed_val)\n",
        "                torch.cuda.manual_seed_all(seed_val)\n",
        "                tokenizer = locals()[f\"get_{model_name.lower()}_tokenizer\"]()\n",
        "                model = locals()[f\"get_{model_name.lower()}_model\"]()\n",
        "                train_text, temp_text = X[train_index], X[test_index]\n",
        "                train_labels, temp_labels = y[train_index], y[test_index]\n",
        "\n",
        "                ########################################################################\n",
        "                #                           Data\n",
        "                ########################################################################                                   \n",
        "                tokens_train = bert_encode(train_text.tolist(), tokenizer, max_seq_len, include_pauses)\n",
        "                tokens_test = bert_encode(temp_text.tolist(), tokenizer, max_seq_len, include_pauses)\n",
        "\n",
        "                #################### Torch Dataset ####################\n",
        "\n",
        "                input_ids = torch.cat(tokens_train['input_ids'], dim=0)\n",
        "                attention_masks = torch.cat(tokens_train['attention_mask'], dim=0)\n",
        "                labels = torch.tensor(train_labels.tolist())\n",
        "\n",
        "                input_ids_test = torch.cat(tokens_test['input_ids'], dim=0)\n",
        "                attention_masks_test = torch.cat(tokens_test['attention_mask'], dim=0)\n",
        "                labels_test = torch.tensor(temp_labels.tolist())\n",
        "\n",
        "                ####################\n",
        "                dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "                train_size = int(0.9 * len(dataset))\n",
        "                val_size = len(dataset) - train_size\n",
        "                train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "                ####################\n",
        "                train_dataloader = DataLoader(\n",
        "                    train_dataset,  # The training samples.\n",
        "                    sampler=RandomSampler(train_dataset),  # Select batches randomly\n",
        "                    batch_size=batch_size_tr  # Trains with this batch size.\n",
        "                )\n",
        "\n",
        "                validation_dataloader = DataLoader(\n",
        "                    val_dataset,  # The validation samples.\n",
        "                    sampler=SequentialSampler(val_dataset),  # Pull out batches sequentially.\n",
        "                    batch_size=batch_size_tr  # Evaluate with this batch size.\n",
        "                )\n",
        "                ###############################################################################\n",
        "\n",
        "                total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "                #################### Training stuff ####################\n",
        "                optimizer = AdamW(model.parameters(),\n",
        "                                lr=lr,  # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                                eps=1e-8  # args.adam_epsilon  - default is 1e-8.\n",
        "                                )\n",
        "\n",
        "                scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                            num_warmup_steps=0,  # Default value in run_glue.py\n",
        "                                                            num_training_steps=total_steps)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                training_stats = []\n",
        "\n",
        "                # Measure the total training time for the whole run.\n",
        "                total_t0 = time.time()\n",
        "\n",
        "                # For each epoch...\n",
        "                for epoch_i in range(0, epochs):\n",
        "\n",
        "                    # ========================================\n",
        "                    #               Training\n",
        "                    # ========================================\n",
        "\n",
        "                    # Perform one full pass over the training set.\n",
        "\n",
        "                    # print(\"\")\n",
        "                    # print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "                    # print('Training...')\n",
        "\n",
        "                    # Measure how long the training epoch takes.\n",
        "                    t0 = time.time()\n",
        "\n",
        "                    # Reset the total loss for this epoch.\n",
        "                    total_train_loss = 0\n",
        "\n",
        "                    # Put the model into training mode. Don't be mislead--the call to\n",
        "                    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "                    # `dropout` and `batchnorm` layers behave differently during training\n",
        "                    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "                    model.train()\n",
        "\n",
        "                    # For each batch of training data...\n",
        "                    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "                        # Progress update every 40 batches.\n",
        "                        if step % 40 == 0 and not step == 0:\n",
        "                            # Calculate elapsed time in minutes.\n",
        "                            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                            # Report progress.\n",
        "                            # print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "                        # Unpack this training batch from our dataloader.\n",
        "                        #\n",
        "                        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "                        # `to` method.\n",
        "                        #\n",
        "                        # `batch` contains three pytorch tensors:\n",
        "                        #   [0]: input ids\n",
        "                        #   [1]: attention masks\n",
        "                        #   [2]: labels\n",
        "                        b_input_ids = batch[0].to(device)\n",
        "                        b_input_mask = batch[1].to(device)\n",
        "                        b_labels = batch[2].to(device)\n",
        "\n",
        "                        # Always clear any previously calculated gradients before performing a\n",
        "                        # backward pass. PyTorch doesn't do this automatically because\n",
        "                        # accumulating the gradients is \"convenient while training RNNs\".\n",
        "                        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "                        model.zero_grad()\n",
        "\n",
        "                        # Perform a forward pass (evaluate the model on this training batch).\n",
        "                        # In PyTorch, calling `model` will in turn call the model's `forward`\n",
        "                        # function and pass down the arguments. The `forward` function is\n",
        "                        # documented here:\n",
        "                        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "                        # The results are returned in a results object, documented here:\n",
        "                        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "                        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "                        # \"logits\"--the model outputs prior to activation.\n",
        "                        try:\n",
        "                            result = model(b_input_ids,\n",
        "                                        token_type_ids=None,\n",
        "                                        attention_mask=b_input_mask,\n",
        "                                        labels=b_labels,\n",
        "                                        return_dict=True)\n",
        "                        except:\n",
        "                            result = model(b_input_ids,\n",
        "                                            #    token_type_ids=None,\n",
        "                                            attention_mask=b_input_mask,\n",
        "                                            labels=b_labels,\n",
        "                                            return_dict=True)                    \n",
        "\n",
        "                        loss = result.loss\n",
        "                        logits = result.logits\n",
        "\n",
        "                        # Accumulate the training loss over all of the batches so that we can\n",
        "                        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "                        # single value; the `.item()` function just returns the Python value\n",
        "                        # from the tensor.\n",
        "                        total_train_loss += loss.item()\n",
        "\n",
        "                        # Perform a backward pass to calculate the gradients.\n",
        "                        loss.backward()\n",
        "\n",
        "                        # Clip the norm of the gradients to 1.0.\n",
        "                        # This is to help prevent the \"exploding gradients\" problem.\n",
        "                        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "                        # Update parameters and take a step using the computed gradient.\n",
        "                        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "                        # modified based on their gradients, the learning rate, etc.\n",
        "                        optimizer.step()\n",
        "\n",
        "                        # Update the learning rate.\n",
        "                        scheduler.step()\n",
        "\n",
        "                    # Calculate the average loss over all of the batches.\n",
        "                    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "                    # Measure how long this epoch took.\n",
        "                    training_time = format_time(time.time() - t0)\n",
        "\n",
        "                    # print(\"\")\n",
        "                    # print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "                    # print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "                    # ========================================\n",
        "                    #               Validation\n",
        "                    # ========================================\n",
        "                    # After the completion of each training epoch, measure our performance on\n",
        "                    # our validation set.\n",
        "\n",
        "                    # print(\"\")\n",
        "                    # print(\"Running Validation...\")\n",
        "\n",
        "                    t0 = time.time()\n",
        "\n",
        "                    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "                    # during evaluation.\n",
        "                    model.eval()\n",
        "\n",
        "                    # Tracking variables\n",
        "                    total_eval_accuracy = 0\n",
        "                    total_eval_loss = 0\n",
        "                    nb_eval_steps = 0\n",
        "\n",
        "                    # Evaluate data for one epoch\n",
        "                    for batch in validation_dataloader:\n",
        "                        # Unpack this training batch from our dataloader.\n",
        "                        #\n",
        "                        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
        "                        # the `to` method.\n",
        "                        #\n",
        "                        # `batch` contains three pytorch tensors:\n",
        "                        #   [0]: input ids\n",
        "                        #   [1]: attention masks\n",
        "                        #   [2]: labels\n",
        "                        b_input_ids = batch[0].to(device)\n",
        "                        b_input_mask = batch[1].to(device)\n",
        "                        b_labels = batch[2].to(device)\n",
        "\n",
        "                        # Tell pytorch not to bother with constructing the compute graph during\n",
        "                        # the forward pass, since this is only needed for backprop (training).\n",
        "                        with torch.no_grad():\n",
        "                            # Forward pass, calculate logit predictions.\n",
        "                            # token_type_ids is the same as the \"segment ids\", which\n",
        "                            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                            result = model(b_input_ids,\n",
        "                                        #    token_type_ids=None,\n",
        "                                        attention_mask=b_input_mask,\n",
        "                                        labels=b_labels,\n",
        "                                        return_dict=True)\n",
        "\n",
        "                        # Get the loss and \"logits\" output by the model. The \"logits\" are the\n",
        "                        # output values prior to applying an activation function like the\n",
        "                        # softmax.\n",
        "                        loss = result.loss\n",
        "                        logits = result.logits\n",
        "\n",
        "                        # Accumulate the validation loss.\n",
        "                        total_eval_loss += loss.item()\n",
        "\n",
        "                        # Move logits and labels to CPU\n",
        "                        logits = logits.detach().cpu().numpy()\n",
        "                        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "                        # Calculate the accuracy for this batch of test sentences, and\n",
        "                        # accumulate it over all batches.\n",
        "                        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "                    # Report the final accuracy for this validation run.\n",
        "                    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "                    # print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "                    # Calculate the average loss over all of the batches.\n",
        "                    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "                    # Measure how long the validation run took.\n",
        "                    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "                    # print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "                    # print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "                    # Record all statistics from this epoch.\n",
        "                    training_stats.append(\n",
        "                        {\n",
        "                            'epoch': epoch_i + 1,\n",
        "                            'Training Loss': avg_train_loss,\n",
        "                            'Valid. Loss': avg_val_loss,\n",
        "                            'Valid. Accur.': avg_val_accuracy,\n",
        "                            'Training Time': training_time,\n",
        "                            'Validation Time': validation_time\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "                # print(\"\")\n",
        "                # print(\"Training complete!\")\n",
        "\n",
        "                # print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))\n",
        "\n",
        "                # Create the DataLoader.\n",
        "                prediction_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "                prediction_sampler = SequentialSampler(prediction_data)\n",
        "                prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size_ts)\n",
        "                ################################################################################\n",
        "                # Prediction on test set\n",
        "\n",
        "                # print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "                # Put model in evaluation mode\n",
        "                model.eval()\n",
        "\n",
        "                # Tracking variables \n",
        "                predictions , true_labels = [], []\n",
        "\n",
        "                # Predict \n",
        "                for batch in prediction_dataloader:\n",
        "                    # Add batch to GPU\n",
        "                    batch = tuple(t.to(device) for t in batch)\n",
        "                \n",
        "                    # Unpack the inputs from our dataloader\n",
        "                    b_input_ids, b_input_mask, b_labels = batch\n",
        "                    \n",
        "                    # Telling the model not to compute or store gradients, saving memory and \n",
        "                    # speeding up prediction\n",
        "                    with torch.no_grad():\n",
        "\n",
        "                        # Forward pass, calculate logit predictions.\n",
        "                        try:\n",
        "                            result = model(b_input_ids, \n",
        "                                            token_type_ids=None, \n",
        "                                            attention_mask=b_input_mask,\n",
        "                                            return_dict=True)\n",
        "                        except:\n",
        "                            result = model(b_input_ids, \n",
        "                                            #  token_type_ids=None, \n",
        "                                            attention_mask=b_input_mask,\n",
        "                                            return_dict=True)\n",
        "\n",
        "                    logits = result.logits\n",
        "\n",
        "                    # Move logits and labels to CPU\n",
        "                    logits = logits.detach().cpu().numpy()\n",
        "                    label_ids = b_labels.to('cpu').numpy()\n",
        "                    \n",
        "                    # Store predictions and true labels\n",
        "                    predictions.append(logits)\n",
        "                    true_labels.append(label_ids)\n",
        "\n",
        "                # print('    DONE.')\n",
        "                ###############################################################################\n",
        "                \n",
        "                f1_set = []\n",
        "                acc_set = []\n",
        "\n",
        "                # Evaluate each test batch using Matthew's correlation coefficient\n",
        "                # print('Calculating Acc and F1 Corr. Coef. for each batch...')\n",
        "\n",
        "                # For each input batch...\n",
        "                for i in range(len(true_labels)):\n",
        "                    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "                    # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "                    # in to a list of 0s and 1s.\n",
        "                    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "                    \n",
        "                    # Calculate and store the acc for this batch.\n",
        "                    acc = accuracy_score(true_labels[i], pred_labels_i)          \n",
        "                    acc_set.append(acc)\n",
        "\n",
        "                    f1 = f1_score(true_labels[i], pred_labels_i)          \n",
        "                    f1_set.append(f1)\n",
        "                    pred += pred_labels_i.tolist()\n",
        "                    target += true_labels[i].tolist()\n",
        "                    #############################################################################\n",
        "                    # Create a barplot showing the Accuracy score for each batch of test samples.\n",
        "                \n",
        "                # print(f\"Acc: {np.mean(acc_set)}\\tF1: {np.mean(f1_set)}\")\n",
        "                total_val_acc += acc_set\n",
        "                total_val_f1 += f1_set\n",
        "            avgacc = np.mean(acc_set)\n",
        "            accuracy_dict[name].append(round(avgacc, 2))\n",
        "            avgf1 = np.mean(f1_set)\n",
        "            f1_dict[name].append(round(avgf1, 2))\n",
        "            print(f\"AVG Acc: {avgacc}\\tAVG F1: {avgf1}\")\n",
        "            total_acc = accuracy_score(total_target, total_preds)\n",
        "            total_f1 = f1_score(total_target, total_preds)\n",
        "            scores = precision_recall_fscore_support(total_target, total_preds, average=None, labels=[0,1])\n",
        "            pr0, pr1 = scores[0]\n",
        "            re0, re1 = scores[1]\n",
        "            f10, f11 = scores[2]\n",
        "            total_acc = accuracy_score(total_target, total_preds)\n",
        "            total_f1 = f1_score(total_target, total_preds)\n",
        "            class1_dict_f1[name].append(f11)\n",
        "            class1_dict_pr[name].append(pr1)\n",
        "            class1_dict_re[name].append(re1)\n",
        "\n",
        "            class0_dict_f1[name].append(f10)\n",
        "            class0_dict_pr[name].append(pr0)\n",
        "            class0_dict_re[name].append(re0)\n",
        "header = \"experiments,0,42,23,avg,std\\n\"\n",
        "output_acc = header[::]\n",
        "output_f1 = header[::]\n",
        "print(\"experiments,0,42,23,avg,std\")\n",
        "for key in accuracy_dict:\n",
        "    values = accuracy_dict[key]\n",
        "    avg_seed_acc = np.mean(values)\n",
        "    stddev = np.std(values)\n",
        "    values += [avg_seed_acc, stddev]\n",
        "    values = \",\".join([str(elem) for elem in values])\n",
        "    output_acc += f\"{key},{values}\\n\"\n",
        "    print(key, \",\", values)\n",
        "print(\"\\n\\n\")\n",
        "print(header)\n",
        "for key in f1_dict:\n",
        "    values = f1_dict[key]\n",
        "    avg_seed_f1 = np.mean(values)\n",
        "    stddev = np.std(values)\n",
        "    values += [avg_seed_f1, stddev]\n",
        "    values = \",\".join([str(elem) for elem in values])\n",
        "    output_f1 += f\"{key},{values}\\n\"\n",
        "    print(key, \",\", values)   \n",
        "with open(\"acc_results_2020pause2.csv\", \"w\") as fptr:\n",
        "    fptr.write(output_acc)\n",
        "    fptr.close()\n",
        "with open(\"f1_results_2020pause2.csv\", \"w\") as fptr:\n",
        "    fptr.write(output_f1)\n",
        "    fptr.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}