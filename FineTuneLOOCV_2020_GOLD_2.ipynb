{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FineTuneLOOCV_2020_GOLD_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshwinDeshpande96/Measuring_the_Impact_of_Verbal_Disfluency_Tags_on_Automated_Dementia_Detection/blob/master/FineTuneLOOCV_2020_GOLD_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8HlwwyCPJSX",
        "outputId": "2228323e-9435-4531-ac9b-46507d701c71"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sePSgdTMuS1w",
        "outputId": "2bb657e2-19e6-4017-e21c-f5c10e6f891c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive/Research/ADReSSo\n",
        "# %cd /content/drive/My\\ Drive/Admission/UIC/Research/Python/Dementia-Detection/Disfluency-Detection/english-fisher-annotations\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Research/ADReSSo\n",
            "/content/drive/My Drive/Research/ADReSSo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5eq2FbbxUkH"
      },
      "source": [
        "# models = ['Bert', 'Roberta', 'DistilBERT']\n",
        "# _ = [print(f\"[{i + 1}] {m}\") for i, m in enumerate(models)]\n",
        "# model_num = int(input(\"Choose model: \")) - 1\n",
        "# if model_num not in range(len(models)):\n",
        "#     raise Exception(\"Incorrect model chosen.\")\n",
        "\n",
        "# model_name = models[model_num]\n",
        "#####################################################################\n",
        "import random\n",
        "import re\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from google.colab import drive\n",
        "import datetime\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "import time\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "from sklearn.model_selection import KFold\n",
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "# drive.mount('/content/drive')\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from transformers import BertTokenizer\n",
        "#################### Global Variables ####################\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "UNUSED_TOKEN = {1: '[unused0]',\n",
        "                2: '[unused1]',\n",
        "                3: '[unused2]'}\n",
        "to_categorical = {'Control': 0,\n",
        "                  'Dementia': 1}\n",
        "\n",
        "################### Train and Test Sets ####################\n",
        "\n",
        "# train_text, temp_text, train_labels, temp_labels = train_test_split(df['transcript'], df['dx'],\n",
        "#                                                                     random_state=seed_val,\n",
        "#                                                                     test_size=0.3,\n",
        "#                                                                     stratify=df['dx'])\n",
        "\n",
        "\n",
        "#################### BERT features ####################\n",
        "\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def get_bert_tokenizer():\n",
        "    \n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_basic_tokenize=False)\n",
        "    tokenizer.add_special_tokens({ \"additional_special_tokens\": [ \"[unused0]\" ] })\n",
        "    return tokenizer\n",
        "\n",
        "def get_roberta_tokenizer():\n",
        "    from transformers import RobertaTokenizer\n",
        "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_basic_tokenize=False)\n",
        "    tokenizer.add_special_tokens({ \"additional_special_tokens\": [ \"[unused0]\" ] })\n",
        "    return tokenizer\n",
        "\n",
        "def get_distilbert_tokenizer():\n",
        "    from transformers import DistilBertTokenizer\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_basic_tokenize=False)\n",
        "    tokenizer.add_special_tokens({ \"additional_special_tokens\": [ \"[unused0]\" ] })\n",
        "    return tokenizer\n",
        "\n",
        "def encode_sentence(transcript, tokenizer):\n",
        "    transcript = re.sub(r\"\\.\\s\", \" [SEP]\", transcript)\n",
        "    tokens = list(tokenizer.tokenize(transcript))\n",
        "    tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    return token_ids\n",
        "\n",
        "\n",
        "def add_padding(input_word_ids, max_seq_len):\n",
        "    input_type = []\n",
        "    for idx, embedding in enumerate(input_word_ids):\n",
        "        embedding_len = len(embedding)\n",
        "        e_input_type = np.ones(embedding_len, dtype=np.int64).tolist()\n",
        "        if embedding_len < max_seq_len:\n",
        "            zeros = np.zeros(max_seq_len - embedding_len, dtype=np.int64).tolist()\n",
        "            e_input_type += zeros\n",
        "            embedding += zeros\n",
        "        elif embedding_len > max_seq_len:\n",
        "            embedding = embedding[:max_seq_len - 1] + [102]\n",
        "            e_input_type = e_input_type[:max_seq_len]\n",
        "        input_type.append(torch.tensor([e_input_type]))\n",
        "        input_word_ids[idx] = torch.tensor([embedding])\n",
        "    return {'input_ids': input_word_ids, 'attention_mask': input_type}\n",
        "\n",
        "\n",
        "def bert_encode(transcripts, tokenizer, max_seq_len):\n",
        "    input_word_ids = [encode_sentence(s, tokenizer)\n",
        "                      for s in transcripts]\n",
        "    input_word_ids = add_padding(input_word_ids, max_seq_len)\n",
        "    return input_word_ids\n",
        "############################# Models ##################################\n",
        "def get_bert_model():\n",
        "    from transformers import BertForSequenceClassification\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        \"bert-base-uncased\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
        "        num_labels=2,  # The number of output labels--2 for binary classification.\n",
        "        # You can increase this for multi-class tasks.\n",
        "        output_attentions=False,  # Whether the model returns attentions weights.\n",
        "        output_hidden_states=False,  # Whether the model returns all hidden-states.\n",
        "    )\n",
        "    model.cuda()\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_roberta_model():\n",
        "    from transformers import RobertaForSequenceClassification\n",
        "    model = RobertaForSequenceClassification.from_pretrained(\n",
        "        \"roberta-base\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
        "        num_labels=2,  # The number of output labels--2 for binary classification.\n",
        "        # You can increase this for multi-class tasks.\n",
        "        output_attentions=False,  # Whether the model returns attentions weights.\n",
        "        output_hidden_states=False,  # Whether the model returns all hidden-states.\n",
        "    )\n",
        "    model.cuda()\n",
        "    return model\n",
        "\n",
        "def get_distilbert_model():\n",
        "    from transformers import DistilBertForSequenceClassification\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\n",
        "        \"distilbert-base-uncased\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
        "        num_labels=2,  # The number of output labels--2 for binary classification.\n",
        "        # You can increase this for multi-class tasks.\n",
        "        output_attentions=False,  # Whether the model returns attentions weights.\n",
        "        output_hidden_states=False,  # Whether the model returns all hidden-states.\n",
        "    )\n",
        "    model.cuda()\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xvqyf2UFeKu"
      },
      "source": [
        "def reps():\n",
        "  df = pd.read_pickle('data2020fisher_reps.pickle')\n",
        "  X1 = df.transcript_without_tags.to_numpy()\n",
        "  X2 = df.transcript_with_stopword_rep.to_numpy()\n",
        "  X3 = df.transcript_with_non_stopword_rep.to_numpy()\n",
        "  X4 = df.transcript_with_no_rep.to_numpy()\n",
        "  X5 = df.transcript_with_no_filled_pauses.to_numpy()\n",
        "  experiments = ['transcript_without_tags',\n",
        "                  'transcript_with_stopword_rep',\n",
        "                  'transcript_with_non_stopword_rep',\n",
        "                  'transcript_with_no_rep',\n",
        "                  'transcript_with_no_filled_pauses']\n",
        "  Xs = [X1, X2, X3, X4, X5]\n",
        "  df.dx = df.dx.apply(lambda x: to_categorical[x])\n",
        "  y = df.dx.to_numpy()\n",
        "  return df, experiments, Xs, y\n",
        "\n",
        "def all_exp():\n",
        "  df = pd.read_pickle('data2020fisher_all.pickle')\n",
        "  experiments = ['transcript_without_tags',\n",
        "                 'transcript_without_underscore',\n",
        "                 'transcript_without_repetition',\n",
        "                 'transcript_without_retracing',\n",
        "                 'transcript_without_disfluency',\n",
        "                ]\n",
        "  X1 = df.transcript_without_tags.to_numpy()\n",
        "  X2 = df.transcript_without_underscore.to_numpy()\n",
        "  X3 = df.transcript_without_repetition.to_numpy()\n",
        "  X4 = df.transcript_without_retracing.to_numpy()\n",
        "  X5 = df.transcript_without_disfluency.to_numpy()\n",
        "  Xs = [X1, X2, X3, X4, X5]\n",
        "  df.dx = df.dx.apply(lambda x: to_categorical[x])\n",
        "  y = df.dx.to_numpy()\n",
        "  return df, experiments, Xs, y\n",
        "def new_data():\n",
        "    df = pd.read_pickle('new_data.pickle').dropna()\n",
        "    df = df[df.both_eremoved != \"placeholder\"]\n",
        "    experiments = ['all_errors', \"e_tagged\", \"rep_eremoved\", \"ret_eremoved\", \"both_eremoved\"]\n",
        "    df.dx = df.dx.apply(lambda x: to_categorical[x])\n",
        "    X1 = df.all_errors.to_numpy()\n",
        "    X2 = df.e_tagged.to_numpy()\n",
        "    X3 = df.rep_eremoved.to_numpy()\n",
        "    X4 = df.ret_eremoved.to_numpy()\n",
        "    X5 = df.both_eremoved.to_numpy()\n",
        "    Xs = [X1, X2, X3, X4, X5]\n",
        "    y = df.dx.to_numpy()\n",
        "    return df, experiments, Xs, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nMLC4h8xCpLj",
        "outputId": "e5522209-b3d6-40bb-9a23-d1211c23ce33"
      },
      "source": [
        "df, experiments, Xs, y = new_data()\n",
        "print(df.shape)\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1138, 15)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utt_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>mmse</th>\n",
              "      <th>disfluency_asr</th>\n",
              "      <th>transcript_with_tags</th>\n",
              "      <th>transcript_tokens</th>\n",
              "      <th>both_errors</th>\n",
              "      <th>both_etype</th>\n",
              "      <th>both_reference_text</th>\n",
              "      <th>asr_text_map</th>\n",
              "      <th>rep_eremoved</th>\n",
              "      <th>all_errors</th>\n",
              "      <th>e_tagged</th>\n",
              "      <th>ret_eremoved</th>\n",
              "      <th>both_eremoved</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>S051_0_2560</td>\n",
              "      <td>0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>we _ 'll _ start _ with _ a _ girl _</td>\n",
              "      <td>*par we 'll start with the girl . \u00150 2560\u0015</td>\n",
              "      <td>[*par, we, 'll, start, with, the, girl, ., \u00150,...</td>\n",
              "      <td>{'[/]': [], '[//]': []}</td>\n",
              "      <td>{'we_1': None, ''ll_1': None, 'start_1': None,...</td>\n",
              "      <td>we 'll start with the girl</td>\n",
              "      <td>[(we, _, we, None), ('ll, _, 'll, None), (star...</td>\n",
              "      <td>we 'll start with a girl</td>\n",
              "      <td>we 'll start with a girl</td>\n",
              "      <td>we 'll start with a girl</td>\n",
              "      <td>we 'll start with a girl</td>\n",
              "      <td>we 'll start with a girl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>855</th>\n",
              "      <td>S087_65133_74985</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>that _ 's _ all _ there _ is _</td>\n",
              "      <td>*par (.) the father is n't comin(g) . \u001565133 7...</td>\n",
              "      <td>[*par, (.), the, father, is, n't, comin(g), .,...</td>\n",
              "      <td>{'[/]': [], '[//]': []}</td>\n",
              "      <td>{'the_1': None, 'father_1': None, 'is_1': None...</td>\n",
              "      <td>the father is n't coming</td>\n",
              "      <td>[(that, _, the, None), ('s, _, father, None), ...</td>\n",
              "      <td>that 's all there is</td>\n",
              "      <td>that 's all there is</td>\n",
              "      <td>that 's all there is</td>\n",
              "      <td>that 's all there is</td>\n",
              "      <td>that 's all there is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>646</th>\n",
              "      <td>S064_22479_25655</td>\n",
              "      <td>0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>and _ the _ windows _ up _</td>\n",
              "      <td>*par and &amp;uh the window 's up . \u001522479 25655\u0015</td>\n",
              "      <td>[*par, and, &amp;uh, the, window, 's, up, ., \u00152247...</td>\n",
              "      <td>{'[/]': [], '[//]': []}</td>\n",
              "      <td>{'and_1': None, 'uh_1': None, 'the_1': None, '...</td>\n",
              "      <td>and uh the window 's up</td>\n",
              "      <td>[(and, _, and, None), (**, None, uh, None), (t...</td>\n",
              "      <td>and the windows up</td>\n",
              "      <td>and the windows up</td>\n",
              "      <td>and the windows up</td>\n",
              "      <td>and the windows up</td>\n",
              "      <td>and the windows up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>S108_100964_107229</td>\n",
              "      <td>1</td>\n",
              "      <td>13.0</td>\n",
              "      <td>existing _ here _ is _ turning _ over _</td>\n",
              "      <td>*par well this thing here is &amp;uh turnin(g) ove...</td>\n",
              "      <td>[*par, well, this, thing, here, is, &amp;uh, turni...</td>\n",
              "      <td>{'[/]': [], '[//]': []}</td>\n",
              "      <td>{'well_1': None, 'this_1': None, 'thing_1': No...</td>\n",
              "      <td>well this thing here is uh turning over</td>\n",
              "      <td>[(****, None, well, None), (****, None, this, ...</td>\n",
              "      <td>existing here is turning over</td>\n",
              "      <td>existing here is turning over</td>\n",
              "      <td>existing here is turning over</td>\n",
              "      <td>existing here is turning over</td>\n",
              "      <td>existing here is turning over</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>S039_36199_38888</td>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>and _ the _ sink _ is _ running _</td>\n",
              "      <td>*par and the &amp;um &amp;uh sink is running over . \u00153...</td>\n",
              "      <td>[*par, and, the, &amp;um, &amp;uh, sink, is, running, ...</td>\n",
              "      <td>{'[/]': [], '[//]': []}</td>\n",
              "      <td>{'and_1': None, 'the_1': None, 'um_1': None, '...</td>\n",
              "      <td>and the um uh sink is running over</td>\n",
              "      <td>[(and, _, and, None), (the, _, the, None), (**...</td>\n",
              "      <td>and the sink is running</td>\n",
              "      <td>and the sink is running</td>\n",
              "      <td>and the sink is running</td>\n",
              "      <td>and the sink is running</td>\n",
              "      <td>and the sink is running</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1135</th>\n",
              "      <td>S110_21121_23565</td>\n",
              "      <td>1</td>\n",
              "      <td>16.0</td>\n",
              "      <td>and _ a _ stool _ is _ turned _ over _</td>\n",
              "      <td>*par and a stool is turned over . \u001521121 23565\u0015</td>\n",
              "      <td>[*par, and, a, stool, is, turned, over, ., \u001521...</td>\n",
              "      <td>{'[/]': [], '[//]': []}</td>\n",
              "      <td>{'and_1': None, 'a_1': None, 'stool_1': None, ...</td>\n",
              "      <td>and a stool is turned over</td>\n",
              "      <td>[(and, _, and, None), (a, _, a, None), (stool,...</td>\n",
              "      <td>and a stool is turned over</td>\n",
              "      <td>and a stool is turned over</td>\n",
              "      <td>and a stool is turned over</td>\n",
              "      <td>and a stool is turned over</td>\n",
              "      <td>and a stool is turned over</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>S041_22863_30896</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>and _ her _ right _ hand _ looks _ like _ she ...</td>\n",
              "      <td>*par and her right hand looks like she 's almo...</td>\n",
              "      <td>[*par, and, her, right, hand, looks, like, she...</td>\n",
              "      <td>{'[/]': [], '[//]': []}</td>\n",
              "      <td>{'and_1': None, 'her_1': None, 'right_1': None...</td>\n",
              "      <td>and her right hand looks like she 's almost uh...</td>\n",
              "      <td>[(and, _, and, None), (her, _, her, None), (ri...</td>\n",
              "      <td>and her right hand looks like she 's almost tr...</td>\n",
              "      <td>and her right hand looks like she 's almost tr...</td>\n",
              "      <td>and her right hand looks like she 's almost tr...</td>\n",
              "      <td>and her right hand looks like she 's almost tr...</td>\n",
              "      <td>and her right hand looks like she 's almost tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>908</th>\n",
              "      <td>S092_51969_53216</td>\n",
              "      <td>1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>no _ that _ 's _ all _</td>\n",
              "      <td>*par no that 's all . [ exc] \u001551969 53216\u0015</td>\n",
              "      <td>[*par, no, that, 's, all, ., [, exc], \u001551969, ...</td>\n",
              "      <td>{'[/]': [], '[//]': []}</td>\n",
              "      <td>{'no_1': None, 'that_1': None, ''s_1': None, '...</td>\n",
              "      <td>no that 's all</td>\n",
              "      <td>[(no, _, no, None), (that, _, that, None), ('s...</td>\n",
              "      <td>no that 's all</td>\n",
              "      <td>no that 's all</td>\n",
              "      <td>no that 's all</td>\n",
              "      <td>no that 's all</td>\n",
              "      <td>no that 's all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>S013_22022_25481</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>you _ want _ like _ the _ windows _ open _ tha...</td>\n",
              "      <td>*par &amp;uh do [/] do you want like the window 's...</td>\n",
              "      <td>[*par, &amp;uh, DOREP, [/], do, you, want, like, t...</td>\n",
              "      <td>{'[/]': [[2]], '[//]': []}</td>\n",
              "      <td>{'uh_1': None, 'DO_1': 'REP', 'do_1': None, 'y...</td>\n",
              "      <td>uh DO do you want like the window 's open that...</td>\n",
              "      <td>[(**, None, uh, None), (**, None, DO, REP), (*...</td>\n",
              "      <td>you want like the windows open that sort of thing</td>\n",
              "      <td>you want like the windows open that sort of thing</td>\n",
              "      <td>you want like the windows open that sort of thing</td>\n",
              "      <td>you want like the windows open that sort of thing</td>\n",
              "      <td>you want like the windows open that sort of thing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1394</th>\n",
              "      <td>S140_63734_66044</td>\n",
              "      <td>1</td>\n",
              "      <td>17.0</td>\n",
              "      <td>selected _ rock _</td>\n",
              "      <td>*par and she must have dropped one . \u001563734 66...</td>\n",
              "      <td>[*par, and, she, must, have, dropped, one, ., ...</td>\n",
              "      <td>{'[/]': [], '[//]': []}</td>\n",
              "      <td>{'and_1': None, 'she_1': None, 'must_1': None,...</td>\n",
              "      <td>and she must have dropped one</td>\n",
              "      <td>[(***, None, and, None), (***, None, she, None...</td>\n",
              "      <td>selected rock</td>\n",
              "      <td>selected rock</td>\n",
              "      <td>selected rock</td>\n",
              "      <td>selected rock</td>\n",
              "      <td>selected rock</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  utt_id  ...                                      both_eremoved\n",
              "501          S051_0_2560  ...                           we 'll start with a girl\n",
              "855     S087_65133_74985  ...                               that 's all there is\n",
              "646     S064_22479_25655  ...                                 and the windows up\n",
              "1095  S108_100964_107229  ...                      existing here is turning over\n",
              "426     S039_36199_38888  ...                            and the sink is running\n",
              "1135    S110_21121_23565  ...                         and a stool is turned over\n",
              "449     S041_22863_30896  ...  and her right hand looks like she 's almost tr...\n",
              "908     S092_51969_53216  ...                                     no that 's all\n",
              "161     S013_22022_25481  ...  you want like the windows open that sort of thing\n",
              "1394    S140_63734_66044  ...                                      selected rock\n",
              "\n",
              "[10 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbF4kWxnIbU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf22770-cb71-48b1-af96-74139a78cf77"
      },
      "source": [
        "model_name = \"bert\"\n",
        "lr = 4e-5\n",
        "max_seq_len = 256\n",
        "epochs = 8\n",
        "# epochs = 1\n",
        "batch_size_tr = 16\n",
        "batch_size_ts = 32\n",
        "from collections import OrderedDict\n",
        "# experiments = ['transcript_without_tags', 'transcript_without_retracing','transcript_without_repetition', 'transcript_without_disfluency']\n",
        "accuracy_dict = OrderedDict(zip(experiments, [[] for _ in range(len(experiments))]))\n",
        "f1_dict = OrderedDict(zip(experiments, [[] for _ in range(len(experiments))]))\n",
        "# class1_dict_acc = OrderedDict(zip(experiments, [[] for _ in range(len(experiments))]))\n",
        "class1_dict_f1 = OrderedDict(zip(experiments, [[] for _ in range(len(experiments))]))\n",
        "class1_dict_pr = OrderedDict(zip(experiments, [[] for _ in range(len(experiments))]))\n",
        "class1_dict_re = OrderedDict(zip(experiments, [[] for _ in range(len(experiments))]))\n",
        "\n",
        "# class0_dict_acc = OrderedDict(zip(experiments, [[] for _ in range(len(experiments))]))\n",
        "class0_dict_f1 = OrderedDict(zip(experiments, [[] for _ in range(len(experiments))]))\n",
        "class0_dict_pr = OrderedDict(zip(experiments, [[] for _ in range(len(experiments))]))\n",
        "class0_dict_re = OrderedDict(zip(experiments, [[] for _ in range(len(experiments))]))\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "\n",
        "# print(f\"SEED: {seed_val}\\nMODEL: {model_name}\\nBATCH SIZE TR: {batch_size_tr}\\nBATCH SIZE TS: {batch_size_ts}\\nLEARNING RATE: {lr}\\nEMBEDDING LEN: {max_seq_len}\\nEPOCH: {epochs}\")\n",
        "for seed_val in [0, 42, 23, 17, 19, 111]:\n",
        "    for name, X in zip(experiments, Xs):\n",
        "        print(\"#\"*10, name)\n",
        "        random.seed(seed_val)\n",
        "        np.random.seed(seed_val)\n",
        "        torch.manual_seed(seed_val)\n",
        "        torch.cuda.manual_seed_all(seed_val)\n",
        "        kf = KFold(n_splits=5, random_state=seed_val, shuffle=True)\n",
        "        total_preds = []\n",
        "        total_target = []\n",
        "        f1_set = []\n",
        "        acc_set = []\n",
        "        fold=1\n",
        "        for train_index, test_index in kf.split(X):\n",
        "            print('fold %d'%(fold))\n",
        "            random.seed(seed_val)\n",
        "            np.random.seed(seed_val)\n",
        "            torch.manual_seed(seed_val)\n",
        "            torch.cuda.manual_seed_all(seed_val)\n",
        "            tokenizer = locals()[f\"get_{model_name.lower()}_tokenizer\"]()\n",
        "            model = locals()[f\"get_{model_name.lower()}_model\"]()\n",
        "            train_text, temp_text = X[train_index], X[test_index]\n",
        "            train_labels, temp_labels = y[train_index], y[test_index]\n",
        "            fold+=1\n",
        "            \n",
        "            tokens_train = bert_encode(train_text.tolist(), tokenizer, max_seq_len)\n",
        "            tokens_test = bert_encode(temp_text.tolist(), tokenizer, max_seq_len)\n",
        "\n",
        "            #################### Torch Dataset ####################\n",
        "\n",
        "            input_ids = torch.cat(tokens_train['input_ids'], dim=0)\n",
        "            attention_masks = torch.cat(tokens_train['attention_mask'], dim=0)\n",
        "            labels = torch.tensor(train_labels.tolist())\n",
        "\n",
        "            input_ids_test = torch.cat(tokens_test['input_ids'], dim=0)\n",
        "            attention_masks_test = torch.cat(tokens_test['attention_mask'], dim=0)\n",
        "            labels_test = torch.tensor(temp_labels.tolist())\n",
        "\n",
        "\n",
        "            ####################\n",
        "            dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "            train_size = int(0.9 * len(dataset))\n",
        "            val_size = len(dataset) - train_size\n",
        "            train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "            ####################\n",
        "            train_dataloader = DataLoader(\n",
        "                train_dataset,  # The training samples.\n",
        "                sampler=RandomSampler(train_dataset),  # Select batches randomly\n",
        "                batch_size=batch_size_tr  # Trains with this batch size.\n",
        "            )\n",
        "\n",
        "            validation_dataloader = DataLoader(\n",
        "                val_dataset,  # The validation samples.\n",
        "                sampler=SequentialSampler(val_dataset),  # Pull out batches sequentially.\n",
        "                batch_size=batch_size_tr  # Evaluate with this batch size.\n",
        "            )\n",
        "            ###############################################################################\n",
        "\n",
        "            total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "            #################### Training stuff ####################\n",
        "            optimizer = AdamW(model.parameters(),\n",
        "                            lr=lr,  # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                            eps=1e-8  # args.adam_epsilon  - default is 1e-8.\n",
        "                            )\n",
        "\n",
        "            scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                        num_warmup_steps=0,  # Default value in run_glue.py\n",
        "                                                        num_training_steps=total_steps)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            training_stats = []\n",
        "\n",
        "            # Measure the total training time for the whole run.\n",
        "            total_t0 = time.time()\n",
        "\n",
        "            # For each epoch...\n",
        "            for epoch_i in range(0, epochs):\n",
        "\n",
        "                # ========================================\n",
        "                #               Training\n",
        "                # ========================================\n",
        "\n",
        "                # Perform one full pass over the training set.\n",
        "\n",
        "                # print(\"\")\n",
        "                # print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "                # print('Training...')\n",
        "\n",
        "                # Measure how long the training epoch takes.\n",
        "                t0 = time.time()\n",
        "\n",
        "                # Reset the total loss for this epoch.\n",
        "                total_train_loss = 0\n",
        "\n",
        "                # Put the model into training mode. Don't be mislead--the call to\n",
        "                # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "                # `dropout` and `batchnorm` layers behave differently during training\n",
        "                # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "                model.train()\n",
        "\n",
        "                # For each batch of training data...\n",
        "                for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "                    # Progress update every 40 batches.\n",
        "                    if step % 40 == 0 and not step == 0:\n",
        "                        # Calculate elapsed time in minutes.\n",
        "                        elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                        # Report progress.\n",
        "                        # print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "                    # Unpack this training batch from our dataloader.\n",
        "                    #\n",
        "                    # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "                    # `to` method.\n",
        "                    #\n",
        "                    # `batch` contains three pytorch tensors:\n",
        "                    #   [0]: input ids\n",
        "                    #   [1]: attention masks\n",
        "                    #   [2]: labels\n",
        "                    b_input_ids = batch[0].to(device)\n",
        "                    b_input_mask = batch[1].to(device)\n",
        "                    b_labels = batch[2].to(device)\n",
        "\n",
        "                    # Always clear any previously calculated gradients before performing a\n",
        "                    # backward pass. PyTorch doesn't do this automatically because\n",
        "                    # accumulating the gradients is \"convenient while training RNNs\".\n",
        "                    # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "                    model.zero_grad()\n",
        "\n",
        "                    # Perform a forward pass (evaluate the model on this training batch).\n",
        "                    # In PyTorch, calling `model` will in turn call the model's `forward`\n",
        "                    # function and pass down the arguments. The `forward` function is\n",
        "                    # documented here:\n",
        "                    # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "                    # The results are returned in a results object, documented here:\n",
        "                    # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "                    # Specifically, we'll get the loss (because we provided labels) and the\n",
        "                    # \"logits\"--the model outputs prior to activation.\n",
        "                    try:\n",
        "                        result = model(b_input_ids,\n",
        "                                    token_type_ids=None,\n",
        "                                    attention_mask=b_input_mask,\n",
        "                                    labels=b_labels,\n",
        "                                    return_dict=True)\n",
        "                    except:\n",
        "                        result = model(b_input_ids,\n",
        "                                        #    token_type_ids=None,\n",
        "                                        attention_mask=b_input_mask,\n",
        "                                        labels=b_labels,\n",
        "                                        return_dict=True)                    \n",
        "\n",
        "                    loss = result.loss\n",
        "                    logits = result.logits\n",
        "\n",
        "                    # Accumulate the training loss over all of the batches so that we can\n",
        "                    # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "                    # single value; the `.item()` function just returns the Python value\n",
        "                    # from the tensor.\n",
        "                    total_train_loss += loss.item()\n",
        "\n",
        "                    # Perform a backward pass to calculate the gradients.\n",
        "                    loss.backward()\n",
        "\n",
        "                    # Clip the norm of the gradients to 1.0.\n",
        "                    # This is to help prevent the \"exploding gradients\" problem.\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "                    # Update parameters and take a step using the computed gradient.\n",
        "                    # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "                    # modified based on their gradients, the learning rate, etc.\n",
        "                    optimizer.step()\n",
        "\n",
        "                    # Update the learning rate.\n",
        "                    scheduler.step()\n",
        "\n",
        "                # Calculate the average loss over all of the batches.\n",
        "                avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "                # Measure how long this epoch took.\n",
        "                training_time = format_time(time.time() - t0)\n",
        "\n",
        "                # print(\"\")\n",
        "                # print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "                # print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "                # ========================================\n",
        "                #               Validation\n",
        "                # ========================================\n",
        "                # After the completion of each training epoch, measure our performance on\n",
        "                # our validation set.\n",
        "\n",
        "                # print(\"\")\n",
        "                # print(\"Running Validation...\")\n",
        "\n",
        "                t0 = time.time()\n",
        "\n",
        "                # Put the model in evaluation mode--the dropout layers behave differently\n",
        "                # during evaluation.\n",
        "                model.eval()\n",
        "\n",
        "                # Tracking variables\n",
        "                total_eval_accuracy = 0\n",
        "                total_eval_loss = 0\n",
        "                nb_eval_steps = 0\n",
        "\n",
        "                # Evaluate data for one epoch\n",
        "                for batch in validation_dataloader:\n",
        "                    # Unpack this training batch from our dataloader.\n",
        "                    #\n",
        "                    # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
        "                    # the `to` method.\n",
        "                    #\n",
        "                    # `batch` contains three pytorch tensors:\n",
        "                    #   [0]: input ids\n",
        "                    #   [1]: attention masks\n",
        "                    #   [2]: labels\n",
        "                    b_input_ids = batch[0].to(device)\n",
        "                    b_input_mask = batch[1].to(device)\n",
        "                    b_labels = batch[2].to(device)\n",
        "\n",
        "                    # Tell pytorch not to bother with constructing the compute graph during\n",
        "                    # the forward pass, since this is only needed for backprop (training).\n",
        "                    with torch.no_grad():\n",
        "                        # Forward pass, calculate logit predictions.\n",
        "                        # token_type_ids is the same as the \"segment ids\", which\n",
        "                        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                        result = model(b_input_ids,\n",
        "                                    #    token_type_ids=None,\n",
        "                                    attention_mask=b_input_mask,\n",
        "                                    labels=b_labels,\n",
        "                                    return_dict=True)\n",
        "\n",
        "                    # Get the loss and \"logits\" output by the model. The \"logits\" are the\n",
        "                    # output values prior to applying an activation function like the\n",
        "                    # softmax.\n",
        "                    loss = result.loss\n",
        "                    logits = result.logits\n",
        "\n",
        "                    # Accumulate the validation loss.\n",
        "                    total_eval_loss += loss.item()\n",
        "\n",
        "                    # Move logits and labels to CPU\n",
        "                    logits = logits.detach().cpu().numpy()\n",
        "                    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "                    # Calculate the accuracy for this batch of test sentences, and\n",
        "                    # accumulate it over all batches.\n",
        "                    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "                # Report the final accuracy for this validation run.\n",
        "                avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "                # print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "                # Calculate the average loss over all of the batches.\n",
        "                avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "                # Measure how long the validation run took.\n",
        "                validation_time = format_time(time.time() - t0)\n",
        "\n",
        "                # print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "                # print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "                # Record all statistics from this epoch.\n",
        "                training_stats.append(\n",
        "                    {\n",
        "                        'epoch': epoch_i + 1,\n",
        "                        'Training Loss': avg_train_loss,\n",
        "                        'Valid. Loss': avg_val_loss,\n",
        "                        'Valid. Accur.': avg_val_accuracy,\n",
        "                        'Training Time': training_time,\n",
        "                        'Validation Time': validation_time\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            # print(\"\")\n",
        "            # print(\"Training complete!\")\n",
        "\n",
        "            # print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))\n",
        "\n",
        "            # Create the DataLoader.\n",
        "            prediction_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "            prediction_sampler = SequentialSampler(prediction_data)\n",
        "            prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size_ts)\n",
        "            ################################################################################\n",
        "            # Prediction on test set\n",
        "\n",
        "            # print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "            # Put model in evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # Tracking variables \n",
        "            predictions , true_labels = [], []\n",
        "\n",
        "            # Predict \n",
        "            for batch in prediction_dataloader:\n",
        "                # Add batch to GPU\n",
        "                batch = tuple(t.to(device) for t in batch)\n",
        "            \n",
        "                # Unpack the inputs from our dataloader\n",
        "                b_input_ids, b_input_mask, b_labels = batch\n",
        "                \n",
        "                # Telling the model not to compute or store gradients, saving memory and \n",
        "                # speeding up prediction\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    # Forward pass, calculate logit predictions.\n",
        "                    try:\n",
        "                        result = model(b_input_ids, \n",
        "                                        token_type_ids=None, \n",
        "                                        attention_mask=b_input_mask,\n",
        "                                        return_dict=True)\n",
        "                    except:\n",
        "                        result = model(b_input_ids, \n",
        "                                        #  token_type_ids=None, \n",
        "                                        attention_mask=b_input_mask,\n",
        "                                        return_dict=True)\n",
        "\n",
        "                logits = result.logits\n",
        "\n",
        "                # Move logits and labels to CPU\n",
        "                logits = logits.detach().cpu().numpy()\n",
        "                label_ids = b_labels.to('cpu').numpy()\n",
        "                \n",
        "                # Store predictions and true labels\n",
        "                predictions.append(logits)\n",
        "                true_labels.append(label_ids)\n",
        "\n",
        "            # print('    DONE.')\n",
        "            ###############################################################################\n",
        "            \n",
        "            \n",
        "\n",
        "            # Evaluate each test batch using Matthew's correlation coefficient\n",
        "            # print('Calculating Acc and F1 Corr. Coef. for each batch...')\n",
        "\n",
        "            # For each input batch...\n",
        "            for i in range(len(true_labels)):\n",
        "                # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "                # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "                # in to a list of 0s and 1s.\n",
        "                pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "                total_target += true_labels[i].tolist()\n",
        "                total_preds += pred_labels_i.tolist()\n",
        "                \n",
        "                # Calculate and store the acc for this batch.\n",
        "                acc = accuracy_score(true_labels[i], pred_labels_i)          \n",
        "                acc_set.append(acc)\n",
        "\n",
        "                f1 = f1_score(true_labels[i], pred_labels_i)\n",
        "                # print(f\"Acc: {acc}\\tF1: {f1}\")          \n",
        "                f1_set.append(f1)\n",
        "                #############################################################################\n",
        "                # Create a barplot showing the Accuracy score for each batch of test samples.\n",
        "        avgacc = np.mean(acc_set)\n",
        "        accuracy_dict[name].append(avgacc)\n",
        "        avgf1 = np.mean(f1_set)\n",
        "        f1_dict[name].append(avgf1)\n",
        "        print(f\"AVG Acc: {avgacc}\\tAVG F1: {avgf1}\")\n",
        "        scores = precision_recall_fscore_support(total_target, total_preds, average=None, labels=[0,1])\n",
        "        pr0, pr1 = scores[0]\n",
        "        re0, re1 = scores[1]\n",
        "        f10, f11 = scores[2]\n",
        "        total_acc = accuracy_score(total_target, total_preds)\n",
        "        total_f1 = f1_score(total_target, total_preds)\n",
        "        class1_dict_f1[name].append(f11)\n",
        "        class1_dict_pr[name].append(pr1)\n",
        "        class1_dict_re[name].append(re1)\n",
        "\n",
        "        class0_dict_f1[name].append(f10)\n",
        "        class0_dict_pr[name].append(pr0)\n",
        "        class0_dict_re[name].append(re0)\n",
        "        \n",
        "        # print(f\"Total Acc: {total_acc}\\tTotal F1: {total_f1}\")\n",
        "        # print(confusion_matrix(total_target, total_preds))\n",
        "header = \"experiments,0,42,23,avg,std\\n\"\n",
        "output_acc = header[::]\n",
        "output_f1 = header[::]\n",
        "class1_acc = header[::]\n",
        "class1_f1 = header[::]\n",
        "class1_pr = header[::]\n",
        "class1_re = header[::]\n",
        "class0_acc = header[::]\n",
        "class0_f1 = header[::]\n",
        "class0_pr = header[::]\n",
        "class0_re = header[::]\n",
        "\n",
        "print(\"acc\")\n",
        "print(header)\n",
        "for key in accuracy_dict:\n",
        "    values = accuracy_dict[key]\n",
        "    values += [np.mean(values), np.std(values)]\n",
        "    values = \",\".join([str(elem) for elem in values])\n",
        "    output_acc += f\"{key},{values}\\n\"\n",
        "    print(key, \",\", values)\n",
        "print(\"\\n\\n\")\n",
        "print(\"f1\")\n",
        "print(header)\n",
        "for key in f1_dict:\n",
        "    values = f1_dict[key]\n",
        "    values += [np.mean(values), np.std(values)]\n",
        "    values = \",\".join([str(elem) for elem in values])\n",
        "    output_f1 += f\"{key},{values}\\n\"\n",
        "    print(key, \",\", values)\n",
        "print(\"\\n\\n\")\n",
        "print(\"c1 f1\")\n",
        "# print(header)\n",
        "# for key in class1_dict_acc:\n",
        "#     values = class1_dict_acc[key]\n",
        "#     values += [np.mean(values), np.std(values)]\n",
        "#     values = \",\".join([str(elem) for elem in values])\n",
        "#     class1_acc += f\"{key},{values}\\n\"\n",
        "#     print(key, \",\", values)  \n",
        "print(header)\n",
        "for key in class1_dict_f1:\n",
        "    values = class1_dict_f1[key]\n",
        "    values += [np.mean(values), np.std(values)]\n",
        "    values = \",\".join([str(elem) for elem in values])\n",
        "    class1_f1 += f\"{key},{values}\\n\"\n",
        "    print(key, \",\", values)\n",
        "print(\"\\n\\n\")\n",
        "print(\"c1 pr\")  \n",
        "print(header)\n",
        "for key in class1_dict_pr:\n",
        "    values = class1_dict_pr[key]\n",
        "    values += [np.mean(values), np.std(values)]\n",
        "    values = \",\".join([str(elem) for elem in values])\n",
        "    class1_pr += f\"{key},{values}\\n\"\n",
        "    print(key, \",\", values)\n",
        "print(\"\\n\\n\")\n",
        "print(\"c1 re\")\n",
        "print(header)\n",
        "for key in class1_dict_re:\n",
        "    values = class1_dict_re[key]\n",
        "    values += [np.mean(values), np.std(values)]\n",
        "    values = \",\".join([str(elem) for elem in values])\n",
        "    class1_re += f\"{key},{values}\\n\"\n",
        "    print(key, \",\", values)\n",
        "print(\"\\n\\n\")\n",
        "print(\"c0 f1\")\n",
        "\n",
        "# print(header)\n",
        "# for key in class0_dict_acc:\n",
        "#     values = class0_dict_acc[key]\n",
        "#     values += [np.mean(values), np.std(values)]\n",
        "#     values = \",\".join([str(elem) for elem in values])\n",
        "#     class0_acc += f\"{key},{values}\\n\"\n",
        "#     print(key, \",\", values)  \n",
        "print(header)\n",
        "for key in class0_dict_f1:\n",
        "    values = class0_dict_f1[key]\n",
        "    values += [np.mean(values), np.std(values)]\n",
        "    values = \",\".join([str(elem) for elem in values])\n",
        "    class0_f1 += f\"{key},{values}\\n\"\n",
        "    print(key, \",\", values) \n",
        "print(\"\\n\\n\")\n",
        "print(\"c0 pr\") \n",
        "print(header)\n",
        "for key in class0_dict_pr:\n",
        "    values = class0_dict_pr[key]\n",
        "    values += [np.mean(values), np.std(values)]\n",
        "    values = \",\".join([str(elem) for elem in values])\n",
        "    class0_pr += f\"{key},{values}\\n\"\n",
        "    print(key, \",\", values)\n",
        "print(\"\\n\\n\")\n",
        "print(\"c0 re\")\n",
        "print(header)\n",
        "for key in class0_dict_re:\n",
        "    values = class0_dict_re[key]\n",
        "    values += [np.mean(values), np.std(values)]\n",
        "    values = \",\".join([str(elem) for elem in values])\n",
        "    class0_re += f\"{key},{values}\\n\"\n",
        "    print(key, \",\", values) \n",
        "with open(\"acc_results_5.csv\", \"w\") as fptr:\n",
        "    fptr.write(output_acc)\n",
        "    fptr.close()\n",
        "with open(\"f1_results_5.csv\", \"w\") as fptr:\n",
        "    fptr.write(output_f1)\n",
        "    fptr.close()\n",
        "\n",
        "# with open(\"class1_acc_results.csv\", \"w\") as fptr:\n",
        "#     fptr.write(class1_acc)\n",
        "#     fptr.close()\n",
        "with open(\"class1_f1_results_5.csv\", \"w\") as fptr:\n",
        "    fptr.write(class1_f1)\n",
        "    fptr.close()\n",
        "with open(\"class1_pr_results_5.csv\", \"w\") as fptr:\n",
        "    fptr.write(class1_pr)\n",
        "    fptr.close()\n",
        "with open(\"class1_re_results_5.csv\", \"w\") as fptr:\n",
        "    fptr.write(class1_re)\n",
        "    fptr.close()\n",
        "\n",
        "# with open(\"class0_acc_results.csv\", \"w\") as fptr:\n",
        "#     fptr.write(class0_acc)\n",
        "#     fptr.close()\n",
        "with open(\"class0_f1_results_5.csv\", \"w\") as fptr:\n",
        "    fptr.write(class0_f1)\n",
        "    fptr.close()\n",
        "with open(\"class0_pr_results_5.csv\", \"w\") as fptr:\n",
        "    fptr.write(class0_pr)\n",
        "    fptr.close()\n",
        "with open(\"class0_re_results_5.csv\", \"w\") as fptr:\n",
        "    fptr.write(class0_re)\n",
        "    fptr.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "########## all_errors\n",
            "fold 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AVG Acc: 0.6484375\tAVG F1: 0.443005330551716\n",
            "########## e_tagged\n",
            "fold 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AVG Acc: 0.640625\tAVG F1: 0.4424089940447817\n",
            "########## rep_eremoved\n",
            "fold 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}